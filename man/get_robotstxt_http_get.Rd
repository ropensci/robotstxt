% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_robotstxt_http_get.R
\docType{data}
\name{rt_last_http}
\alias{rt_last_http}
\alias{get_robotstxt_http_get}
\title{Storage for HTTP request response objects}
\format{
An object of class \code{environment} of length 1.
}
\usage{
rt_last_http

get_robotstxt_http_get(
  domain,
  user_agent = utils::sessionInfo()$R.version$version.string,
  ssl_verifypeer = 1
)
}
\arguments{
\item{domain}{the domain to get robots.txt file for.}

\item{user_agent}{the user agent to use for HTTP request header. Defaults to current version of R.
If `NULL` is passed, httr will use software versions for the header, such as
`libcurl/8.7.1 r-curl/5.2.3 httr/1.4.7`}

\item{ssl_verifypeer}{either 1 (default) or 0, if 0 it disables SSL peer verification, which
might help with robots.txt file retrieval}
}
\description{
Storage for HTTP request response objects

Execute HTTP request for get_robotstxt()
}
\keyword{datasets}
